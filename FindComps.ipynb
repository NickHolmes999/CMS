{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas requests ipykernel  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\":{\"id\":\"ES_qvsc3doo7518r438o0p017hag2\"},\"meta\":{\"httpStatus\":\"200 - OK\",\"requestId\":\"0f2d3e66-af42-4310-826b-81a5632c1a8d\"}}\n",
      "Download is 100.0 complete\n",
      "{\"result\":{\"id\":\"ES_7v0mr4a3ujg28tpb5qq1a22ep3\"},\"meta\":{\"httpStatus\":\"200 - OK\",\"requestId\":\"d6f9a5c4-98e2-491f-854b-955d9108daf8\"}}\n",
      "Download is 100.0 complete\n"
     ]
    }
   ],
   "source": [
    "#Examples in cells below of how to compare across Awareness Comp and Halo\n",
    "#Run first to create helper funcs\n",
    "\n",
    "import pandas as pd\n",
    "import qualtricsapi as qa\n",
    "    \n",
    "token=qa.get_secrets()\n",
    "\n",
    "\n",
    "df_aw=qa.getResults(qa.SetSurveyId.survey_choices['Awareness'],token)\n",
    "df_aw.to_csv('aw.csv')\n",
    "\n",
    "df_comp = qa.getResults(qa.SetSurveyId.survey_choices['Competency'],token)\n",
    "df_comp.to_csv('comp.csv')\n",
    "\n",
    "\n",
    "\n",
    "def eligible_comp_track(track, level = \"Level One\", OIT_only = None , Halo = True, df_aw=None, df_comp=None):\n",
    "    if df_aw is None or df_aw.empty:\n",
    "        df_aw=qa.getResults(qa.SetSurveyId.survey_choices['Awareness'],token)\n",
    "        #df_aw.to_csv('aw.csv')\n",
    "    if df_comp is None or df_comp.empty:\n",
    "        df_comp = qa.getResults(qa.SetSurveyId.survey_choices['Competency'],token)\n",
    "        #df_comp.to_csv('comp.csv')\n",
    "\n",
    "    aw_query = \"Track == @track & Dropped != 'Yes'\"\n",
    "    comp_query = \"Track == @track & Dropped != 'Yes' & Level == @level\"\n",
    "    #To do: Add support for multiple Levels\n",
    "\n",
    "    if Halo:\n",
    "        aw_query = aw_query + \"& Halo == 'Yes'\"\n",
    "\n",
    "    if OIT_only == 'Only':\n",
    "        aw_query = aw_query + \"& Group != 'Other (please specify)'\"\n",
    "        comp_query = comp_query + \"& Group != 'Other (please specify)'\"\n",
    "    \n",
    "    elif OIT_only == 'Other':\n",
    "        aw_query = aw_query + \"& Group == 'Other (please specify)'\"\n",
    "        comp_query = comp_query + \"& Group == 'Other (please specify)'\"\n",
    "\n",
    "    else:\n",
    "        print(f\"OIT only {OIT_only} not a valid option, ASSUMING ALL\")\n",
    "\n",
    "   \n",
    "\n",
    "    df_eligible = (df_aw.query(aw_query)\n",
    "                .merge(df_comp.query(comp_query),how='left', left_on='Email Embedded', right_on='Email Embedded', indicator=True)\n",
    "                .query(\"_merge == 'left_only'\")\n",
    "                .loc[:,'Email Embedded']\n",
    "                .to_frame()\n",
    "                .rename({'Email Embedded': 'Email'}, axis=1)\n",
    "                #To do: Are we copying the dataframe?\n",
    "                .reset_index(drop = True)\n",
    "    )\n",
    "    return df_eligible\n",
    "\n",
    "def eligible_comp_all(df_aw=None, df_comp=None, token=None, OIT_only = None, Halo = True):\n",
    "    if df_aw is None or df_aw.empty:\n",
    "        df_aw = qa.getResults(qa.SetSurveyId.survey_choices['Awareness'], token)\n",
    "        #df_aw.to_csv('aw.csv')\n",
    "    if df_comp is None or df_comp.empty:\n",
    "        df_comp = qa.getResults(qa.SetSurveyId.survey_choices['Competency'], token)\n",
    "        #df_comp.to_csv('comp.csv')\n",
    "    \n",
    "    tracks = ['Data Science',\n",
    "              'Product Management', 'Cloud', 'Human-Centered Design',\n",
    "              'Cyber-Hygiene: Advanced Topics', 'Leadership',\n",
    "              'Artificial Intelligence and Machine Learning']\n",
    "    df_eligible = pd.DataFrame(columns=['track','Email','Group','Halo'])\n",
    "    for track in tracks:\n",
    "        df_track = eligible_comp_track(track,df_aw=df_aw,df_comp=df_comp, OIT_only = OIT_only, Halo = Halo)  # make sure eligible_comp_track is defined elsewhere\n",
    "        df_track['track'] = track\n",
    "        df_eligible = pd.concat([df_eligible,df_track],ignore_index=True)\n",
    "    \n",
    "    return df_eligible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\":{\"id\":\"ES_upepolkrabbi8ujn91ortegv08\"},\"meta\":{\"httpStatus\":\"200 - OK\",\"requestId\":\"ebf0d77d-d65b-46f7-a745-e29ea2784e40\"}}\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 100.0 complete\n",
      "{\"result\":{\"id\":\"ES_m3qmb6qqpquel9ogglcp8blib0\"},\"meta\":{\"httpStatus\":\"200 - OK\",\"requestId\":\"1e053685-7cde-4084-a957-f119ee2750f3\"}}\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 0.0 complete\n",
      "Download is 100.0 complete\n",
      "OIT only None not a valid option, ASSUMING ALL\n"
     ]
    }
   ],
   "source": [
    "'''OIT_only = None is All | OIT_only = Only | OIT_only = Other'''\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "eligible_comp_track('Human-Centered Design', OIT_only = 'None').to_csv('HCD-Comp-VS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OIT only True not a valid option, ASSUMING ALL\n",
      "OIT only True not a valid option, ASSUMING ALL\n",
      "OIT only True not a valid option, ASSUMING ALL\n",
      "OIT only True not a valid option, ASSUMING ALL\n",
      "OIT only True not a valid option, ASSUMING ALL\n",
      "OIT only True not a valid option, ASSUMING ALL\n",
      "OIT only True not a valid option, ASSUMING ALL\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "comp_output = eligible_comp_all(df_aw=df_aw,df_comp=df_comp,OIT_only = True, Halo = False)\n",
    "#print(comp_output[\"Email\"].nunique())\n",
    "comp_output.to_csv(\"comp_eligible.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#&  Halo != 'Yes' & `Repeat Learner Embedded` == 'No'\"\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "df_no_halo = df_aw.query(\"`Verified Complete` == 'Yes' & Halo !='Yes' & Group == ['AMG','BOG', 'EADG','ESSG','ICPG','ISPG','IUSG','OIT Front Office']\" )\n",
    "df_no_halo[\"Email Embedded\"].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find \n",
    "df_comp_data = df_comp.query(\"Track == 'Data Science' & `Verified Complete` == 'Yes'\")\n",
    "df_leadership = (df_aw.query(\"Track == 'Data Science' & `Verified Complete` == 'Yes' & Halo == 'Yes'\")\n",
    "                .merge(df_comp_leadership,how='left', left_on='Email Embedded', right_on='Email Embedded', indicator=True)\n",
    "                .query(\"_merge == 'left_only'\")\n",
    "                .loc[:,'Email Embedded']\n",
    ")\n",
    "df_leadership.to_csv(\"data1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_comp_leadership = df_comp.query(\"Track == 'Leadership' & `Verified Complete` == 'Yes'\")\n",
    "df_leadership = (df_aw.query(\"Track == 'Leadership' & Season == 'Spring 2023' & Session == 'Session 2' & Halo == 'Yes'\")\n",
    "               .merge(df_comp_leadership,how='left', left_on='Email Embedded', right_on='Email Embedded', indicator=True)\n",
    "              .query(\"_merge == 'left_only'\")\n",
    "              .loc[:,'Email Embedded']\n",
    ")\n",
    "df_leadership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We dont collect this any more\n",
    "df_pm_complete = (df_aw.query(\"Track == 'Data Science' & `Verified Complete` == 'Yes' & Halo == 'Yes'\"))\n",
    "df_pm_int = (df_aw.query(\"`Awareness Interest_3` == 'Somewhat Interested' | `Awareness Interest_3` == 'Yes'\")\n",
    "                .merge(df_pm_complete, how='left', left_on='Email Embedded', right_on='Email Embedded', indicator=True)\n",
    "                .query(\"_merge == 'left_only'\")\n",
    "                .loc[:,'Email Embedded']\n",
    "                .drop_duplicates() )\n",
    "df_pm_int.to_clipboard()\n",
    "print(df_pm_int)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None\n",
    "if x:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
